Current cuda device:  0
/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/learning/train_part.py:197: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=amp_enabled)
[Hydra] loss_func ▶ SSIMLoss()
[Hydra] Scheduler ▶ <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7a465ab99590>
/home/swpants05/Desktop/2025_FastMri/Data/train
/home/swpants05/Desktop/2025_FastMri/Data/val
Epoch # 0 ............... varnet_small ...............
Epoch[ 0/5]/:   0%|                          | 0/4937 [00:00<?, ?it/s]/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/learning/train_part.py:63: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
True 1
  with autocast(enabled=amp_enabled):
/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/model/varnet.py:286: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /pytorch/aten/src/ATen/native/TensorCompare.cpp:611.)
  soft_dc = torch.where(mask, current_kspace - ref_kspace, zero) * self.dc_weight
max alloc MB: 6181.61376953125
/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.
  _future_warning(
Epoch[ 0/5]/:   0%|    | 16/4937 [00:09<44:54,  1.83it/s, loss=0.2994]
True 1
max alloc MB: 6205.09765625
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
max alloc MB: 7149.341796875
True 1
  File "/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/main.py", line 142, in <module>
    main()
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/main.py", line 135, in main
    train(args)   # utils.learning.train_part.train 호출 :contentReference[oaicite:2]{index=2}
    ^^^^^^^^^^^
  File "/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/learning/train_part.py", line 226, in train
    train_loss, train_time = train_epoch(args, epoch, model,
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/learning/train_part.py", line 64, in train_epoch
    output = model(kspace, mask)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/model/varnet.py", line 243, in forward
    kspace_pred = cascade(kspace_pred, masked_kspace, mask, sens_maps)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/model/varnet.py", line 285, in forward
    zero = torch.zeros(1, 1, 1, 1, 1).to(current_kspace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
