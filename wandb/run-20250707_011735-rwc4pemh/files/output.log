Current cuda device:  0
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
[Hydra] Optimizer â–¶ AdaBelief
[Resume] Loaded '/home/swpants05/Desktop/2025_FastMri/result/small_varnet_resume_test/checkpoints/model.pt' â†’ epoch 2, best_val_loss=0.2964
/home/swpants05/Desktop/2025_FastMri/2025_GeekSeek/utils/learning/train_part.py:212: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=amp_enabled)
[Hydra] loss_func â–¶ SSIMLoss()
[Hydra] Scheduler â–¶ <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x78dc7452b210>
/home/swpants05/Desktop/2025_FastMri/Data/train
/home/swpants05/Desktop/2025_FastMri/Data/val
